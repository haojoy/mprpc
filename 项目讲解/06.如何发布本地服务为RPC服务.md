# 服务端发布服务

假设已经有了一个 rpc 框架，我们是 rpc 服务的提供者，我们本地有一个服务，现在想利用我们的 rpc 框架将这个服务变成 rpc 服务。那么我们会经历如下的操作。

1. 写 proto 文件，描述这个服务的请求消息，返回消息，服务方法。
2. 经过命令生成 pb 文件，protobuf 为我们自动生成了代码。
3. 我们需要重写函数

```cpp
// 一个本地服务，现在要将它变成rpc服务
class UserService : public fixbug::UserServiceRpc // rpc服务提供者
{
public:
    bool Login(const std::string& name, const std::string& pwd)
    {
        std::cout << "doing local service: Login" << std::endl;
        std::cout << "name:" << name << "pwd:" << pwd << std::endl;
    }

    void Login(::google::protobuf::RpcController* controller,
                    const ::fixbug::LoginRequest* request,
                    ::fixbug::LoginResponse* response,
                    ::google::protobuf::Closure* done)
    {
        // 框架给业务上报了请求参数 LoginRequest，应用获取数据进行业务
        std::string name = request->name();
        std::string pwd = request->pwd();

        // 此处是本地业务
        bool login_result = Login(name, pwd);

        // 把响应写入
        fixbug::ResultCode *code = response->mutable_result();
        code->set_errcode(0);
        code->set_errmsg("success");
        response->set_success(login_result);

        // 执行回调操作
        // hi行响应对象数据的序列化和网络发送
        done->Run();
    }

};

int main(int argc, char **argv)
{
    // 调用框架的初始化操作
    MprpcApplication::Init(argc, argv);
    
    // provider是一个rpc网络服务对象，把userService对象发布到rpc节点上
    RpcProvider provider;
    provider.NotifyService(new UserService());

    // 启动一个rpc发布节点，进入阻塞状态等待远处rpc请求
    provider.Run();

    return 0;
}
```

1. 对 RPC 框架进行初始化操作，配置信息通过命令行传递
2. 生成一个 provider 对象，用于将业务发布到 RPC 节点上
3. 启动 RPC 发布节点，阻塞等待远程 RPC 请求

我们希望使用者可以轻松，简便的上手。于是初步定了使用方法，后面的实现也会按照这个「框架」来实现。

网络服务由 muduo 库提供，我们将 TcpServer 对象组合到 MprpcProvider 类中。然后重写给的各类回调函数，在这类回调函数中，我们会实现 RPC 业务。

# MprpcProvider

之前我们展示了服务端发布服务的代码，接下来我们还需要探究 MprpcProvider 的内部实现。

那么我们的服务端会利用 MprpcProvider  来注册服务，之前的 `provider.NotifyService(new UserService());` 代码就是这个意思。而 MprpcProvider 需要支持发布所有服务，因此 NotifyService 方法接收参数必须被设计为这些服务的基类，即`google::protobuf::Service`。这样我们传递各类服务，都会被转换为基类指针，其实就是运行多态。按照 Java 的话来说，我们需要一个「接口」。

之前提到过，protobuf 只是提供了数据的序列化/反序列化和 RPC 接口，但是并没有提供网络传输相关代码。而在这个项目中，我们发送和接收数据包的操作由 muduo 库来完成。我们需要注册回调函数来处理不同的事件。

这里主要关注「连接相关」事件和「有消息到来」事件。因此 MprpcProvider 还需要注册不同事件的回调函数，需要实现「连接到来/关闭」和「收到新消息」时的处理操作。

MprpcProvider 类的源码

```cpp
class MprpcProvider
{
public:
    // 框架，需要设计成抽象基类
    void NotifyService(google::protobuf::Service *service);

    // 启动rpc服务节点，开始提供rpc远程网络调用服务
    void Run();

private:
    // 连接相关事件
    void OnConnection(const muduo::net::TcpConnectionPtr&);
    // 已建立连接用户的读写事件回调
    void OnMessage(const muduo::net::TcpConnectionPtr&, muduo::net::Buffer*, muduo::Timestamp);
    // Closure 的回调操作，用于序列化rpc的响应和网络发送
    void SendRpcResponse(const muduo::net::TcpConnectionPtr&, google::protobuf::Message*);

    // 单个服务的信息
    struct ServiceInfo
    {
        // 服务对象
        google::protobuf::Service *m_service;
        // 服务方法
        std::unordered_map<std::string, const google::protobuf::MethodDescriptor*> m_methodMap;
    };
    // 存储注册成功的服务对象和服务方法的所有信息
    std::unordered_map<std::string, ServiceInfo> m_serviceMap;
    // 使用智能指针管理
    std::unique_ptr<muduo::net::TcpServer> m_tcpserverPtr;
    muduo::net::EventLoop m_eventLoop;
};
```

# NotifyService

1. 使用 NotifyService 发布某个服务
2. 从 Service 指针中获取服务描述，使用接口由 protobuf 提供。我们可以从服务描述中获取该 RPC 服务的名称，该 RPC 服务所有的方法，方法总数等信息。
3. 遍历 Service 中的 rpc method，将其注册到我们的 methodMap 中。最后将其加入到服务对象集合中 m_serviceMap。

```cpp
// 框架，需要设计成抽象基类
void MprpcProvider::NotifyService(google::protobuf::Service *service) 
{
    ServiceInfo service_info;

    // 获取服务对象的描述信息
    const google::protobuf::ServiceDescriptor *pserviceDesc = service->GetDescriptor();
    // 获取服务的名字
    // 需包含 google/protobuf/descriptor.h 
    std::string service_name = pserviceDesc->name();
    // 获取服务对象service的方法的数量
    int methodCnt = pserviceDesc->method_count();

    service_info.m_service = service;
    m_serviceMap.insert({service_name, service_info});
}
```

# 正式开启远程服务

1. 从 RPC 框架中获取 RPC 服务的 IP 地址和端口号，我们需要地址信息去开启一个 TcpServer。
2. 设置线程数量，注册 TcpServer 的连接相关事件回调函数和消息到来的回调函数。
3. 我们之前注册服务的时候，会将服务相关信息存储到 ServiceInfo 中，现在正式启动了，我们需要将信息储存到 zookeeper 上用于服务发现。
4. 启动 TcpServer 并开启事件循环。

```cpp
// 启动rpc服务节点，开始提供rpc远程网络调用服务
void MprpcProvider::Run() 
{
    std::string ip = MprpcApplication::GetInstance().GetConfig().Load("rpc_server_ip");
    uint16_t port = atoi(MprpcApplication::GetInstance().GetConfig().Load("rpc_server_port").c_str());
    muduo::net::InetAddress address(ip, port);

    // 创建 TcpServer 对象
    muduo::net::TcpServer server(&m_eventLoop, address, "RpcProvider");

    // 设置muduo库线程数量
    server.setThreadNum(4);

    // 绑定连接回调和消息读写回调方法  分离了网络代码和业务代码
    server.setConnectionCallback(std::bind(&MprpcProvider::OnConnection, this, std::placeholders::_1));
    server.setMessageCallback(std::bind(&MprpcProvider::OnMessage, this, std::placeholders::_1, 
            std::placeholders::_2, std::placeholders::_3));

    // 把当前rpc节点上要发布的服务全部注册到zk上面，让rpc client可以从zk上发现服务
    ZkClient zkCli;
    zkCli.Start();
    // service_name为永久性节点，method_name为临时性节点
    for (auto &sp : m_serviceMap) 
    {
        // /UserServiceRpc
        std::string service_path = "/" + sp.first;
        zkCli.Create(service_path.c_str(), nullptr, 0);
        for (auto &mp : sp.second.m_methodMap)
        {
            // path = /UserServiceRpc/Login 
            // value = 127.0.0.1:2181
            std::string method_path = service_path + "/" + mp.first;
            char method_path_data[128] = {0};
            sprintf(method_path_data, "%s:%d", ip.c_str(), 2181);
            // ZOO_EPHEMERAL表示znode是一个临时性节点
            zkCli.Create(method_path.c_str(), method_path_data, strlen(method_path_data), ZOO_EPHEMERAL);
        }
    }
    
    std::cout << "RpcProvider start service at ip:" << ip << " port:" << port << std::endl;

    // 启动网络服务
    server.start();
    m_eventLoop.loop();
}
```

# 当有请求到来时

当有请求数据到来时，onMessage 回调函数会被调用。我们接收调用 RPC 客户端传送来的数据流，从中获取信息并直到它要调用哪个服务，哪个方法，参数是什么？

应用端网络传输数据避免不了 TCP 黏包的问题，这可能会出现如下几种情况。

1. 客户端发送数据过多，一次服务的消息在 TCP 层分片了，我们接收的数据包没有包含本次服务的所有信息。
2. 客户端发送数据较少，多次服务的信息在一个数据包里，我们一次接收的数据包含了好几个服务的信息。

如果我们对于这些数据不加处理（比如中间没有标识或阻隔），直接接收。那么我们会不知道哪一块才是我们想要的信息。有可能与一次性读多了数据，读到别的服务信息了。

因此在设计时，需要设置自定义的协议。业界的主流协议的解决方案可以归纳如下：

1. 消息定长，例如每个报文的大小为固定长度100字节，如果不够用空格补足。
2. 在包尾特殊结束符进行分割。
3. 将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段。

这里采用第三种，我们增加消息头，并规定其占据四个字节，里面标注了这个本次服务信息的大小。我们每次先读取前四个字节，获取这次服务请求信息的总大小，然后就知道我们接下来还要读多少数据了。

![img](https://cdn.nlark.com/yuque/0/2022/png/26752078/1659632133965-40f4522a-82b0-4651-adeb-f3801fb23dd0.png)

1. 读取前四个字节到 `header_size` 中，里面的内容就是这个包实际内容的大小了
2. `recv_buf.substr(4, header_size);` 跳过前面提示大小的四个字节，按照 `header_size` 大小往后截断包的内容，将此内容存储到 `rpc_header_str` 中。
3. `mprpc::RpcHeader rpcHeader` 反序列化 `rpc_header_str` ，获取想要的内容。分别是服务名称，方法名称和传入参数的大小。
4. 继续获取传入参数的信息，之前获取了参数的大小。`std::string args_str = recv_buf.substr(4 + header_size, args_size)`

```cpp
void MprpcProvider::OnMessage(const muduo::net::TcpConnectionPtr& conn, 
                                muduo::net::Buffer* buffer,
                                muduo::Timestamp timestamp)
{
    // 网络上接受的远程rpc调用请求的字符流
    std::string recv_buf = buffer->retrieveAllAsString();    

    // 从字符流中读取前四个字节的内容
    uint32_t header_size = 0;
    // 从字符流种拷贝前四个字节(char占据一个字节)内容到header_size地址头处
    // 因为header_size是uin32_t类型，因此指针需要强制转换
    char* address = (char*)&header_size;
    recv_buf.copy(address, 4, 0);

    // copy[4, 4 + header_size) -> rpc_header_str
    // 也就是本次服务的信息 service_name + method_name + args_size
    std::string rpc_header_str = recv_buf.substr(4, header_size);
    mprpc::RpcHeader rpcHeader;
    std::string service_name;
    std::string method_name;
    uint32_t args_size;

    // 数据反序列化
    if (rpcHeader.ParseFromString(rpc_header_str))
    {
        service_name = rpcHeader.service_name();
        method_name = rpcHeader.methon_name();
        args_size = rpcHeader.args_size();
    }
    else 
    {
        std::cout << "rpc_header_str:" << rpc_header_str << " parse error!" << std::endl; 
        return;
    }

    // 接下来还要继续获取传递参数内容
    std::string args_str = recv_buf.substr(4 + header_size, args_size);
}
```

根据我们获取到的服务名信息，在我们的注册表`serviceMap`中查找。查找到有这个服务之后，再去查找该服务是否含有调用方法。

最后再获取此服务和方法，这里就使用了 protobuf 为我们提供的类。Service 和 MethodDescriptor。调用他们内置的方法生成请求和响应对象，将其作为回调函数需要的参数。

```cpp
google::protobuf::Message *request = service->GetRequestPrototype(method).New();
google::protobuf::Message *response = service->GetResponsePrototype(method).New();

// 为 done 绑定回调函数
// Closure:闭包
google::protobuf::Closure *done 
	= google::protobuf::NewCallback<MprpcProvider, 
                                    const muduo::net::TcpConnectionPtr&, 
                                    google::protobuf::Message*>
                                    (this, 
                                    &MprpcProvider::SendRpcResponse, 
                                    conn, response);

// 在框架上根据远端rpc请求，调用当前rpc节点上发布的方法
// new UserService().Login(controller, request, response, done)
service->CallMethod(method, nullptr, request, response, done);
```

当 `service->CallMethod()` 执行完毕后，就会调用 done 绑定的回调函数。这里绑定的是 `MprpcProvider::SendRpcResponse`。会将服务的结果序列化，然后通过 muduo 网络库发送给客户端。

```cpp
// Closure的回调操作，用于序列化rpc的响应和网络发送
void MprpcProvider::SendRpcResponse(const muduo::net::TcpConnectionPtr& conn, 
                                    google::protobuf::Message* response)
{
    std::string response_str;
    if (response->SerializeToString(&response_str))
    {
        // 序列化成功后，通过网络将rpc方法执行结果发送给rpc的调用方
        conn->send(response_str);
    }
    else
    {
        std::cout << "serialize response_str error!" << std::endl;
    }
    // 半关闭
    conn->shutdown();
}
```